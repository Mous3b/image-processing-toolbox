{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/anshulp2912/PhotoEditor-OpenCV/blob/master/source/PhotoEditor_opencv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lly78rHT7K8C"
   },
   "source": [
    "# <center><font color='red'>mohamed samir toolbox USING OPEN-CV COMMANDS</font></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMZc4xnGBq4c"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "colab_type": "code",
    "id": "0N2QzEhFr4vU",
    "outputId": "317832ac-3e7d-4261-cd5b-19562e7bfc6a"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab.patches import cv2_imshow\n",
    "from PIL import Image \n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYaKlcIxBvGj",
    "tags": []
   },
   "source": [
    "## Define Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMvmSsObCJst"
   },
   "source": [
    "### Blur Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4C9CRPyOU7Uz"
   },
   "outputs": [],
   "source": [
    "def blur_filter(image_path):\n",
    "  image = cv2.imread(image_path)\n",
    "  image = cv2.GaussianBlur(image,(5,5),cv2.BORDER_DEFAULT)\n",
    "  #cv2_imshow(image)\n",
    "  cv2.imwrite('temp.jpg',image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ds6tnLvtCMPJ"
   },
   "source": [
    "### Edge Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPSwpkf8VZx0"
   },
   "outputs": [],
   "source": [
    "def edge_filter(image_path):\n",
    "  image = cv2.imread(image_path)\n",
    "  image = cv2.Canny(image,100,300)\n",
    "  #cv2_imshow(image)\n",
    "  cv2.imwrite('temp.jpg',image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHa-Bm8nCQ0j"
   },
   "source": [
    "### Black & White Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rd5mTL5eKL52"
   },
   "outputs": [],
   "source": [
    "def blackwhite_filter(image_path):\n",
    "    \n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "  #cv2_imshow(image)\n",
    "    cv2.imwrite('temp.jpg',image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Affine transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### translation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation (image_path,tx,ty):\n",
    "    \n",
    "    image=cv2.imread(image_path)\n",
    "    rows,cols,ch=image.shape\n",
    "    tran=np.float32([[1,0,tx],[0,1,ty]])\n",
    "    trans=cv2.warpAffine(image,tran,(cols,rows))\n",
    "    cv2.imwrite('temp.jpg',trans)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### rotation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation (image_path,ang):\n",
    "    image=cv2.imread(image_path)\n",
    "    rows,cols,ch=image.shape\n",
    "    rot=cv2.getRotationMatrix2D((cols/2,rows/2),ang,1)\n",
    "    rotated=cv2.warpAffine(image,rot,(cols,rows))\n",
    "    res=cv2.resize(rotated,(cols,rows))\n",
    "    cv2.imwrite('temp.jpg',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot (imageInput,ang):\n",
    "    # image_inp = Image.fromarray(imageInput)\n",
    "    # image_inp.save(\"temp.jpg\") \n",
    "    # image = cv2.imread(\"temp.jpg\")\n",
    "    # image = cv2.resize(image,(800,800))\n",
    "    img = cv2.imread(imageInput,0)\n",
    "    # cv2.imwrite('temp.jpg', img)\n",
    "    # if ang!=0.00:\n",
    "    #     rotation('temp.jpg',ang)\n",
    "    \n",
    "    rows,cols=img.shape\n",
    "    rot=cv2.getRotationMatrix2D((cols/2,rows/2),ang,1)\n",
    "    rotated=cv2.warpAffine(img,rot,(cols,rows))\n",
    "    cv2.imwrite('temp.jpg',rotated)\n",
    "    # im = Image.open('temp.jpg')\n",
    "    # return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### flipping function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(image_path,f):\n",
    "    image=cv2.imread(image_path)\n",
    "    if f==0:\n",
    "        fl=cv2.flip(image,0)\n",
    "    elif f==1:\n",
    "        fl=cv2.flip(image,1)\n",
    "    elif f==-1:\n",
    "        fl=cv2.flip(image,-1)\n",
    "    cv2.imwrite('temp.jpg',fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### cropping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image,x,y):\n",
    "    img=cv2.imread(image,0)\n",
    "    rows, cols = img.shape\n",
    "    crop=img[x:,y:]\n",
    "    # resize=cv2.resize(crop,(cols,rows))\n",
    "    cv2.imwrite('temp.jpg',crop)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### deskewing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjuEpEHUGNbs"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sek(image,s1,s2,x1,y1):\n",
    "    \n",
    "    img=cv2.imread(image,0)\n",
    "    rows, cols = img.shape\n",
    "    p1=np.float32([[0,0]\n",
    "                ,  [cols-1,0],\n",
    "                   [0,rows-1]])\n",
    "    p2=np.float32([[0,0],\n",
    "                   [cols-1,s1],\n",
    "                   [s2,rows-1]])\n",
    "    p=cv2.getAffineTransform(p1,p2)\n",
    "    resk=cv2.warpAffine(img,p,(cols,rows))\n",
    "    cv2.imwrite('temp.jpg',resk)\n",
    "    if x1|y1!=0.00:\n",
    "        crop('temp.jpg',x1,y1)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Point processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### blending function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blending(image_path,srcp,a,b):\n",
    "    \n",
    "    image=cv2.imread(image_path,0)\n",
    "    rows,cols=image.shape\n",
    "    src=cv2.imread(srcp,0)\n",
    "    imr=cv2.resize(src,(cols,rows))\n",
    "    bl=cv2.addWeighted(src1=image,alpha=a,src2=imr,beta=b,gamma=0)\n",
    "    cv2.imwrite('temp.jpg',bl)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belfn(im1,im2,a,b):\n",
    "    \n",
    "    # image_inp1 = Image.fromarray(im1)\n",
    "    # image_inp1.save(\"temp.jpg\") \n",
    "    # image1 = cv2.imread(\"temp.jpg\")\n",
    "    # image1 = cv2.resize(image1,(800,800))\n",
    "    image1 = cv2.imread(im1)\n",
    "    cv2.imwrite('temp.jpg', image1)\n",
    "    # image_inp2 = Image.fromarray(im2)\n",
    "    # image_inp2.save(\"temp2.jpg\") \n",
    "    # image2 = cv2.imread(\"temp2.jpg\")\n",
    "    # image2 = cv2.resize(image2,(800,800))\n",
    "    image2 = cv2.imread(im2)\n",
    "    cv2.imwrite('temp2.jpg', image2)\n",
    "    if a or b!=0.00:\n",
    "        blending('temp.jpg',\"temp2.jpg\",a,b)\n",
    "    im= Image.open('temp.jpg')\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### negative function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative(image_path):\n",
    "    image=cv2.imread(image_path)\n",
    "    neg=255-image\n",
    "    cv2.imwrite('temp.jpg',neg)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  log transfromation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_trans(image_path):\n",
    "    image=cv2.imread(image_path)\n",
    "    c=255/np.log(1+np.max(image))\n",
    "    limg=c*(np.log(1+image))\n",
    "    limg=np.array(limg,dtype = np.uint8)\n",
    "    cv2.imwrite('temp.jpg',limg)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  power law function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_law(image_path,p):\n",
    "    image=cv2.imread(image_path)\n",
    "    gamm = np.array(255 * (image / 255) ** p, dtype='uint8')\n",
    "    cv2.imwrite('temp.jpg',gamm)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def histogram(imageInput):\n",
    "#     image_inp = Image.fromarray(imageInput)\n",
    "#     image_inp.save(\"temp.jpg\") \n",
    "#     image = cv2.imread(\"temp.jpg\")\n",
    "#     image = cv2.resize(image,(800,800))\n",
    "#     cv2.imwrite('temp.jpg', image)\n",
    "#     image2=cv2.imread('temp.jpg')       \n",
    "#     hist2 = cv2.calcHist([image2],[0],None,[256],[0,256])     \n",
    "#     img=plt.figure()\n",
    "#     plt.plot(hist2, color='b')\n",
    "#     return img        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  histogram function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(imageInput):\n",
    "    # image_inp = Image.fromarray(imageInput)\n",
    "    # image_inp.save(\"temp.jpg\") \n",
    "    # image = cv2.imread(\"temp.jpg\")\n",
    "    # image = cv2.resize(image,(800,800))\n",
    "    # cv2.imwrite('temp.jpg', image)\n",
    "    image2=cv2.imread(imageInput,0)       \n",
    "    hist2 = cv2.calcHist([image2],[0],None,[256],[0,256])     \n",
    "    img=plt.figure()\n",
    "    plt.plot(hist2, color='b')\n",
    "    return img        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  histogram equlaization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histequl(img):\n",
    "    image=cv2.imread(img,0)\n",
    "    equ = cv2.equalizeHist(image)\n",
    "    cv2.imwrite('temp.jpg',equ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def histeq(image_path):\n",
    "#     image=cv2.imread(image_path,0)\n",
    "#     equ = cv2.equalizeHist(image)\n",
    "#     cv2.imwrite('temp.jpg',equ)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  gray level slicing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graylvl(image_path,mini,maxi):    \n",
    "    image=cv2.imread(image_path,0)\n",
    "    rows,cols=image.shape[:2]\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (image[r][c]>mini and image[r][c]<=maxi):\n",
    "                image[r][c]=255\n",
    "            else:\n",
    "                image[r][c]=0\n",
    "    cv2.imwrite('temp.jpg',image)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  bit plane slicing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitslic(image_path,b):\n",
    "    image2=cv2.imread(image_path,0) \n",
    "    rows, cols = image2.shape\n",
    "    bit=int(pow(b,2))\n",
    "    if bit!=0:\n",
    "        \n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if ((image2[r][c]&bit).all()):\n",
    "                    image2[r][c]=255\n",
    "                else:\n",
    "                    image2[r][c]=0\n",
    "        cv2.imwrite('temp.jpg', image2)\n",
    "    else:\n",
    "        cv2.imwrite('temp.jpg', image2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traditional(image_path,k):\n",
    "    image=cv2.imread(image_path)\n",
    "    kernal=np.ones((k,k),np.float32)\n",
    "    sumk=int(kernal.sum())\n",
    "    kernal=kernal/sumk\n",
    "    result=cv2.filter2D(image,-1,kernal)\n",
    "    cv2.imwrite('temp.jpg',result)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(image_path,k):\n",
    "    image=cv2.imread(image_path,0)\n",
    "    gaussian_blur = cv2.GaussianBlur(src=image, ksize=(k,k),sigmaX=0, sigmaY=0)\n",
    "    cv2.imwrite('temp.jpg',gaussian_blur)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(image_path,k):\n",
    "    image=cv2.imread(image_path,0)\n",
    "    median = cv2.medianBlur(image,k)\n",
    "    cv2.imwrite('temp.jpg',median)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharp(image_path):\n",
    "    image=cv2.imread(image_path,0)\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5,-1],\n",
    "                   [0, -1, 0]])\n",
    "    image_sharp = cv2.filter2D(src=image, ddepth=-1, kernel=kernel)\n",
    "    cv2.imwrite('temp.jpg',image_sharp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular(image_path):\n",
    "    image=cv2.imread(image_path,0)\n",
    "    kerc=np.array([[0,1,0],\n",
    "              [1,1,1],\n",
    "              [0,1,0]])/5\n",
    "    rescir=cv2.filter2D(image,-1,kerc)\n",
    "    cv2.imwrite('temp.jpg',rescir)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramidical(image_path):\n",
    "    image=cv2.imread(image_path,0)\n",
    "    kerpar=np.array([\n",
    "              [1,2,3,2,1],\n",
    "              [2,4,6,4,2],\n",
    "              [3,6,9,6,3],\n",
    "              [2,4,6,4,2],\n",
    "              [1,2,3,2,1]])/81\n",
    "    respar=cv2.filter2D(image,-1,kerpar)\n",
    "    cv2.imwrite('temp.jpg',respar)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confilter(image_path):\n",
    "    image=cv2.imread(image_path,0)\n",
    "    kercon=np.array([[0,0,1,0,0],\n",
    "              [0,2,2,2,0],\n",
    "              [1,2,5,2,1],\n",
    "              [0,2,2,2,0],\n",
    "              [0,0,1,0,0]])/25\n",
    "    rescon=cv2.filter2D(image,-1,kercon)\n",
    "    cv2.imwrite('temp.jpg',rescon)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laplacian(image_path,k):\n",
    "    ddepth = cv2.CV_64F\n",
    "    image=cv2.imread(image_path,0)\n",
    "    dst = cv2.Laplacian(image, ddepth, ksize=k)\n",
    "    abs_dst = cv2.convertScaleAbs(dst)#converting back to CV_8U\n",
    "    cv2.imwrite('temp.jpg',abs_dst)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_1(image_path,c,k):\n",
    "    \n",
    "    ddepth = cv2.CV_64F\n",
    "    img=cv2.imread(image_path,0)\n",
    "    # img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    if c==0:\n",
    "        soble=cv2.Sobel(img,ddepth,1,0,ksize=k)\n",
    "        cv2.imwrite('temp.jpg',soble)   \n",
    "    if c==1:\n",
    "        soble=cv2.Sobel(img,ddepth,0,1,ksize=k)\n",
    "        cv2.imwrite('temp.jpg',soble)   \n",
    "    if c==2:\n",
    "        soblex=cv2.Sobel(img,ddepth,1,0,ksize=k)\n",
    "        sobley=cv2.Sobel(img,ddepth,0,1,ksize=k)\n",
    "        soble=cv2.addWeighted(soblex, 0.5, sobley, 0.5, 0)\n",
    "        cv2.imwrite('temp.jpg',soble)   \n",
    "    # soble_x_y=np.hstack((soble_x,soble_y))\n",
    "    # cv2.imwrite('temp.jpg',soble)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh_1(image_path,c,th):\n",
    "    img=cv2.imread(image_path,0)\n",
    "    if c==0:\n",
    "        ret, thresh = cv2.threshold(img, th, 255, cv2.THRESH_BINARY)\n",
    "    if c==1:\n",
    "        ret, thresh = cv2.threshold(img, th, 255, cv2.THRESH_BINARY_INV)\n",
    "    if c==2:\n",
    "        ret, thresh = cv2.threshold(img, th, 255, cv2.THRESH_TRUNC)\n",
    "    if c==3:\n",
    "        ret, thresh = cv2.threshold(img, th, 255, cv2.THRESH_TOZERO)\n",
    "    if c==4:   \n",
    "        ret, thresh = cv2.threshold(img, th, 255, cv2.THRESH_TOZERO_INV)\n",
    "    cv2.imwrite('temp.jpg',thresh)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def smoothing(imageInput,k_t,k_g,k_m,k_l,sobel,k_s,thersh,th,filters):\n",
    "#     image_inp = Image.fromarray(imageInput)\n",
    "#     image_inp.save(\"temp.jpg\") \n",
    "#     image = cv2.imread(\"temp.jpg\")\n",
    "#     image = cv2.resize(image,(800,800))\n",
    "#     cv2.imwrite('temp.jpg', image)\n",
    "    \n",
    "#     if k_t!=0.00:\n",
    "#         traditional('temp.jpg',k_t)\n",
    "#     if k_g!=0.00:\n",
    "#         gaussian('temp.jpg',k_g)\n",
    "#     if k_m!=0.00:\n",
    "#         median('temp.jpg',k_m)\n",
    "#     if k_l !=0.00:\n",
    "#         Laplacian('temp.jpg',k_l)\n",
    "#     if sobel :\n",
    "#         if \"sobel of x\" in sobel:\n",
    "#             if k_s!=0.00:\n",
    "#                 sobel_1('temp.jpg',0,k_s)\n",
    "#         elif \"sobel of y\"in sobel:\n",
    "#             if k_s!=0.00:\n",
    "#                 sobel_1('temp.jpg',1,k_s)\n",
    "#         elif \"sobel of x and y\"in sobel: \n",
    "#             if k_s!=0.00:\n",
    "#                 sobel_1('temp.jpg',2,k_s)\n",
    "#     if th!=0.00:\n",
    "#         if thersh:\n",
    "#             if \"THRESH_BINARY\" in thersh:\n",
    "#                 thresh_1('temp.jpg',0,th)\n",
    "                \n",
    "#             if   \"THRESH_BINARY_INV\" in thersh:\n",
    "#                 thresh_1('temp.jpg',1,th)\n",
    "#             if \"THRESH_TRUNC\" in thersh:\n",
    "#                 thresh_1('temp.jpg',2,th)\n",
    "#             if \"THRESH_TOZERO\" in thersh:\n",
    "#                 thresh_1('temp.jpg',3,th)\n",
    "#             if \"THRESH_TOZERO_INV\" in thersh:\n",
    "#                 thresh_1('temp.jpg',4,th)\n",
    "\n",
    "#     if filters != 0:\n",
    "#         if \"sharpening\" in filters:\n",
    "#             sharp('temp.jpg')\n",
    "#         if \"circular\" in filters:\n",
    "#             circular('temp.jpg')\n",
    "#         if \"pyramidical\" in filters:\n",
    "#             pyramidical('temp.jpg')\n",
    "#         if \"confilter\" in filters:\n",
    "#             confilter('temp.jpg')\n",
    "#     im = Image.open('temp.jpg')\n",
    "#     return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image_path,x,y):\n",
    "    img=cv2.imread(image_path,0) \n",
    "    rows,cols=img.shape\n",
    "    scal=cv2.resize(img,(0, 0), fx = x, fy = y)\n",
    "    cv2.imwrite(\"temp.jpg\",scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rst(imageInput):\n",
    "    # image_inp = Image.fromarray(imageInput)\n",
    "    # image_inp.save(\"temp.jpg\") \n",
    "    # image = cv2.imread(\"temp.jpg\",0)\n",
    "    # image = cv2.resize(image,(800,800))\n",
    "    img = cv2.imread(imageInput,0)\n",
    "    cv2.imwrite('temp.jpg', img)\n",
    "    \n",
    "    im = Image.open('temp.jpg')\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(imageInput):\n",
    "    # image_inp = Image.fromarray(imageInput)\n",
    "    # image_inp.save(\"temp.jpg\") \n",
    "    # image = cv2.imread(\"temp.jpg\")\n",
    "    # image = cv2.resize(image,(800,800))\n",
    "    # cv2.imwrite('temp.jpg', image)\n",
    "    img = cv2.imread(imageInput,0)\n",
    "    # img=cv2.imread(imageInput,0)\n",
    "\n",
    "    _, thresh = cv2.threshold(img, 240, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    white = np.ones((img.shape[0], img.shape[1], 3))\n",
    "\n",
    "    for i,c in enumerate(contours):\n",
    "        if i==0:\n",
    "            continue\n",
    "        approx = cv2.approxPolyDP(c, 0.01*cv2.arcLength(c, True), True)\n",
    "        cv2.drawContours(img, [approx], 0, (0, 0, 255), 5)\n",
    "        x,y,w,h=cv2.boundingRect(approx)\n",
    "        xm=int(x+w/3)\n",
    "        ym=int(y+h/3)\n",
    "        if len(approx) == 3:\n",
    "            cv2.putText(img, \"Triangle\", (xm, ym),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        elif len(approx) == 4:\n",
    "            x1, y1, w, h = cv2.boundingRect(approx)\n",
    "            aspect_ratio = float(w) / float(h)\n",
    "            # print(aspect_ratio)\n",
    "            if aspect_ratio >= 0.95 and aspect_ratio <= 1.05:\n",
    "                cv2.putText(img, \"Square\", (xm, ym),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(img, \"Rectangle\", (xm, ym),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        elif len(approx) == 5:\n",
    "                cv2.putText(img, \"Pentagon\", (xm, ym),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        elif len(approx) == 10:\n",
    "            cv2.putText(img, \"Star\", (xm, ym),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        elif len(approx) == 12:\n",
    "            cv2.putText(img, \"Star\", (xm, ym),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(img, \"Circle\", (xm, ym),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)      \n",
    "            \n",
    "    cv2.imwrite('temp.jpg', img)    \n",
    "    im = Image.open('temp.jpg')\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yuQnPDQECWjB"
   },
   "source": [
    "## PHOTO EDITOR MAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_bOe-NVHIU7"
   },
   "outputs": [],
   "source": [
    "def photoEditor(imageInput,tx,ty ,ang,flipp,power ,mini,maxi,bit,s1,s2,x1,y1,brightnessValue, contrastValue,effectList,\n",
    "                k_t,k_g,k_m,k_l,sobel,k_s,thersh,th,filters,det,trans,log,neg,xs,ys):\n",
    "    \n",
    "\n",
    "    # image_inp = Image.fromarray(imageInput)\n",
    "    # image_inp.save(\"temp.jpg\") \n",
    "    image = cv2.imread(imageInput,0)\n",
    "    # image = cv2.resize(image,(800,800))\n",
    "    cv2.imwrite('temp.jpg', image)\n",
    "    \n",
    "    if xs|ys!=0.00:\n",
    "        scale('temp.jpg',xs,ys)\n",
    "    if tx|ty!=0.00:\n",
    "        translation ('temp.jpg',tx,ty)\n",
    "    if ang!=0.00:\n",
    "        rot('temp.jpg',ang)\n",
    "    if flipp:\n",
    "        if \"flip around x\" in flipp:\n",
    "            flip('temp.jpg',0)\n",
    "            \n",
    "        elif \"flip around y\" in flipp:\n",
    "            flip('temp.jpg',1)\n",
    "        elif \"flip around both\" in flipp:\n",
    "            flip('temp.jpg',-1)\n",
    "        elif \"reset\" in flipp:\n",
    "            cv2.imwrite('temp.jpg', image)\n",
    "    if det :\n",
    "        detect('temp.jpg')\n",
    "    if power!=0.00:\n",
    "        power_law('temp.jpg',power)\n",
    "    if  mini |maxi!=0.0:\n",
    "        graylvl('temp.jpg',mini,maxi)\n",
    "    if bit!=0:\n",
    "        bitslic('temp.jpg',bit)\n",
    "    if s1|s2!=0.00:\n",
    "        sek('temp.jpg',s1,s2,x1,y1)\n",
    "    if contrastValue != 0.00:\n",
    "        contrast_control('temp.jpg',contrastValue)\n",
    "\n",
    "    if brightnessValue != 0.00:\n",
    "    \n",
    "        brightness_control('temp.jpg',brightnessValue)\n",
    "    if trans :    \n",
    "        # if \"histogram equlaization\" in trans:\n",
    "        histequl('temp.jpg')\n",
    "    if log:\n",
    "        log_trans('temp.jpg')\n",
    "    if neg:\n",
    "        negative('temp.jpg')\n",
    "   \n",
    "    if len(effectList) != 0:\n",
    "        \n",
    "        if 'Edge' in effectList:\n",
    "            edge_filter('temp.jpg')\n",
    "\n",
    "        if 'Blur' in effectList:\n",
    "            blur_filter('temp.jpg')\n",
    "\n",
    "        if 'Black & White' in effectList:\n",
    "            blackwhite_filter('temp.jpg')\n",
    "        # if \"negative image\" in effectList:\n",
    "        #     negative('temp.jpg')\n",
    "        # if \"log transformation\" in effectList:\n",
    "        #     log_trans('temp.jpg')\n",
    "        # if \"histogram equlization\" in effectList:\n",
    "        #     histeq('temp.jpg')\n",
    "        \n",
    "    # if det:\n",
    "    #     detect('temp.jpg')\n",
    "    #########################################################################\n",
    "    if k_t!=0.00:\n",
    "        traditional('temp.jpg',k_t)\n",
    "    if k_g!=0.00:\n",
    "        gaussian('temp.jpg',k_g)\n",
    "    if k_m!=0.00:\n",
    "        median('temp.jpg',k_m)\n",
    "    if k_l !=0.00:\n",
    "        Laplacian('temp.jpg',k_l)\n",
    "    if sobel :\n",
    "        if \"sobel of x\" in sobel:\n",
    "            if k_s!=0.00:\n",
    "                sobel_1('temp.jpg',0,k_s)\n",
    "        elif \"sobel of y\"in sobel:\n",
    "            if k_s!=0.00:\n",
    "                sobel_1('temp.jpg',1,k_s)\n",
    "        elif \"sobel of x and y\"in sobel: \n",
    "            if k_s!=0.00:\n",
    "                sobel_1('temp.jpg',2,k_s)\n",
    "    if th!=0.00:\n",
    "        if thersh:\n",
    "            if \"THRESH_BINARY\" in thersh:\n",
    "                thresh_1('temp.jpg',0,th)\n",
    "                \n",
    "            if   \"THRESH_BINARY_INV\" in thersh:\n",
    "                thresh_1('temp.jpg',1,th)\n",
    "            if \"THRESH_TRUNC\" in thersh:\n",
    "                thresh_1('temp.jpg',2,th)\n",
    "            if \"THRESH_TOZERO\" in thersh:\n",
    "                thresh_1('temp.jpg',3,th)\n",
    "            if \"THRESH_TOZERO_INV\" in thersh:\n",
    "                thresh_1('temp.jpg',4,th)\n",
    "\n",
    "    if filters != 0:\n",
    "        if \"sharpening\" in filters:\n",
    "            sharp('temp.jpg')\n",
    "        if \"circular\" in filters:\n",
    "            circular('temp.jpg')\n",
    "        if \"pyramidical\" in filters:\n",
    "            pyramidical('temp.jpg')\n",
    "        if \"confilter\" in filters:\n",
    "            confilter('temp.jpg')    \n",
    "            \n",
    "    im = Image.open('temp.jpg')\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtiG5wNxDSH6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PZT6EcOOCb1n"
   },
   "source": [
    "### GRADIO PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mgLi8tcI5vM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\study\\conda\\lib\\site-packages\\gradio\\inputs.py:256: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "E:\\study\\conda\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "E:\\study\\conda\\lib\\site-packages\\gradio\\outputs.py:42: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "imageInput = gr.inputs.Image(label='Upload an Image')\n",
    "imageInput2 = gr.inputs.Image(label='Upload an Image')\n",
    "# power = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='power law transformation')\n",
    "# ming=gr.inputs.Slider(minimum=-100, maximum=255, default=0, label='min gray lvl')\n",
    "# maxg=gr.inputs.Slider(minimum=-100, maximum=255, default=0, label='max gray lvl')\n",
    "# tx = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='tx')\n",
    "# ty = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='ty')\n",
    "# flipp=gr.inputs.Radio([\"flip around x\",\"flip around y\",\"flip around both\",\"reset\"],label=\"flipping\")\n",
    "# brightnessSlider = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='Brightness')\n",
    "# contrastSlider = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='Contrast')\n",
    "# effectCheckboxes = gr.inputs.CheckboxGroup([\"Edge\", \"Blur\", \"Black & White\",\"negative image\",\"log transformation\",\"histogram equlization\"], label='Effects')\n",
    "####################################################\n",
    "\n",
    "imageOutput =[ gr.outputs.Image(type=\"pil\")]\n",
    "imageOutput2 =[ gr.outputs.Image(type=\"pil\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-P1e_K71Cevi"
   },
   "source": [
    "### Launch PhotoEditor Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "colab_type": "code",
    "id": "VfLgGv7jI5sO",
    "outputId": "e98645e8-0f53-49a8-bccb-afcd7cb7070c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\study\\conda\\lib\\site-packages\\gradio\\inputs.py:120: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "E:\\study\\conda\\lib\\site-packages\\gradio\\inputs.py:88: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "E:\\study\\conda\\lib\\site-packages\\gradio\\inputs.py:148: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "E:\\study\\conda\\lib\\site-packages\\gradio\\deprecation.py:43: UserWarning: You have unused kwarg parameters in Button, please remove them: {'open': False}\n",
      "  warnings.warn(\n",
      "E:\\study\\conda\\lib\\site-packages\\gradio\\inputs.py:216: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "E:\\study\\conda\\lib\\site-packages\\gradio\\deprecation.py:43: UserWarning: You have unused kwarg parameters in Slider, please remove them: {'default': 0}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs=gr.Image()\n",
    "plot=gr.Plot()\n",
    "\n",
    "with gr.Blocks(css=\".gradio-container {background-image: url('file=css-backgrounds.jpg')}\") as demo:\n",
    "    \n",
    "    with gr.Row():\n",
    "        imageInput = gr.inputs.Image(type='filepath',label='Upload an Image')\n",
    "        imageOutput2 =[ gr.outputs.Image(type='pil',label='Output')]\n",
    "    with gr.Row():\n",
    "        image_buttonf = gr.Button(\"submit\")\n",
    "        image_buttonr = gr.Button(\"reset\")\n",
    "        det=gr.inputs.Checkbox(label=\"Detect shapes\")\n",
    "        # det=gr.Button(\"detection\")\n",
    "        # det.click(fn=detect,inputs=imageInput,outputs=imageOutput2)\n",
    "    with gr.Tab(\"EDITE\"):\n",
    "        # with gr.Row():\n",
    "        #     imageInput = gr.inputs.Image(label='Upload an Image')\n",
    "        #     imageOutput2 =[ gr.outputs.Image(type=\"pil\")]\n",
    "        # with gr.Row():\n",
    "        #     image_buttonf = gr.Button(\"submit\")\n",
    "        #     image_buttonr = gr.Button(\"reset\")\n",
    "        with gr.Accordion(\"Affine transformations\",open=False):         \n",
    "            with gr.Accordion(\"Translation\",open=False):\n",
    "                tx = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='tx')\n",
    "                ty = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='ty')\n",
    "            ##############################################################################\n",
    "            with gr.Accordion(\"Rotation\",open=False):\n",
    "                #image_in = gr.Image()\n",
    "                ang=gr.inputs.Slider(minimum=-100,maximum=100,default=0,label=\"ang\")\n",
    "                # #image_output_rot = gr.Image()\n",
    "                # image_button = gr.Button(\"rotate\")\n",
    "                # image_button.click(rot, inputs=[imageInput,ang], outputs=imageOutput2) \n",
    "            #################################################################################\n",
    "            with gr.Accordion(\"deskewing\",open=False):\n",
    "                s1=gr.inputs.Slider(minimum=-100, maximum=500, default=0, label='s1')\n",
    "                s2=gr.inputs.Slider(minimum=-100, maximum=500, default=0, label='s2')\n",
    "                with gr.Accordion(\"croping\",open=False):\n",
    "                    x1=gr.inputs.Slider(minimum=-100, maximum=200, default=0, label='x')\n",
    "                    y1=gr.inputs.Slider(minimum=-100, maximum=200, default=0, label='y')\n",
    "            ################################################################        ######\n",
    "            with gr.Accordion(\"flipping\",open=False):\n",
    "                flipp=gr.inputs.CheckboxGroup([\"flip around x\",\"flip around y\",\"flip around both\"])\n",
    "            ##############################################################\n",
    "            with gr.Accordion(\"scaling\"):\n",
    "                xs=gr.inputs.Slider(label=\"xs\")\n",
    "                ys=gr.inputs.Slider(label=\"ys\")\n",
    "\n",
    "        with gr.Accordion('Point processing',open=False):\n",
    "            with gr.Accordion(\"blending\",open=False):\n",
    "                \n",
    "                # image1 = gr.Image()\n",
    "                image2 = gr.Image(type='filepath',label='Upload the blending Image')\n",
    "                a=gr.inputs.Slider(minimum=0,maximum=1,default=0,label=\"alpha\")\n",
    "                b=gr.inputs.Slider(minimum=0,maximum=1,default=0,label=\"beta\")\n",
    "                image_button = gr.Button(\"BLEND\",open=False)\n",
    "                image_button.click(belfn, inputs=[imageInput,image2,a,b], outputs=imageOutput2) \n",
    "        ######################################################################\n",
    "            log=gr.inputs.Checkbox(label=\"log transformation\")\n",
    "            neg=gr.inputs.Checkbox(label=\"negative image\")\n",
    "            with gr.Accordion('power law transformation',open=False):\n",
    "                power = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='value')\n",
    "            #########\n",
    "            ######################################################################\n",
    "        # #########################\n",
    "            with gr.Accordion(\"gray lvl slicing\",open=False):\n",
    "                ming=gr.inputs.Slider(minimum=0, maximum=255, default=0, label='min gray lvl')\n",
    "                maxg=gr.inputs.Slider(minimum=0, maximum=255, default=0, label='max gray lvl')\n",
    "            ######################################################################\n",
    "            with gr.Accordion(\"Bit plane slicing\",open=False):\n",
    "                bits=gr.inputs.Dropdown(choices=[0,1,2,3,4,5,6,7,8],default=0,type=\"value\")\n",
    "            ######################################################################\n",
    "            with gr.Accordion(\"histogram\",open=False):\n",
    "                # histeq=gr.inputs.Checkbox(label=\"histogram equlization\")\n",
    "                hist=gr.inputs.Checkbox(label=[\"histogram equlaization\"])\n",
    "                plot=gr.Plot()\n",
    "                \n",
    "                histb=gr.Button(\"histogram\")\n",
    "                histb.click(fn=histogram,inputs=[imageInput],outputs=plot)\n",
    "            ######################################################################\n",
    "        brightnessSlider = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='Brightness')\n",
    "        contrastSlider = gr.inputs.Slider(minimum=-100, maximum=100, default=0, label='Contrast')\n",
    "        effectCheckboxes = gr.inputs.CheckboxGroup([\"Edge\", \"Blur\", \"Black & White\"], label='Effects')\n",
    "        \n",
    "        # BTN=gr.Button(\"histogram\")\n",
    "        \n",
    "        # # BTN=gr.Button(\"hist\")\n",
    "        # BTN.click(histogram,inputs=inputs,outputs=plot)\n",
    "        # # image_buttonf = gr.Button(\"submit\")\n",
    "            \n",
    "        # image_buttonf.click(photoEditor, inputs=[imageInput,tx,ty,flipp,power,ming,maxg,bits,brightnessSlider,contrastSlider,effectCheckboxes,\n",
    "        #                                          k_t,k_g,k_m,k_l,sob,k_s,THRESH,th,filters], \n",
    "        #                     outputs=imageOutput2) \n",
    "        image_buttonr.click(rst,inputs=[imageInput],outputs=imageOutput2)\n",
    "       \n",
    "# gr.Interface(fn=photoEditor,inputs=[imageInput,tx,ty,flipp,power,ming,maxg,brightnessSlider,contrastSlider,effectCheckboxes],outputs=imageOutput2)\n",
    "    ##########################################################filters######################################################################\n",
    "\n",
    "    with gr.Tab(\"Image Enhancement\"):\n",
    "        gr.Markdown(\"\"\"\n",
    "                        Note:\n",
    "                         #To use edge based method(Image segmentation) we apply gaussian filter then Laplacian.\n",
    "                         \"\"\")\n",
    "        # with gr.Row():\n",
    "        #     imageInputs = gr.inputs.Image(label='Upload an Image')\n",
    "        #     imageOutputs =[ gr.outputs.Image(type=\"pil\")]\n",
    "        # with gr.Row():\n",
    "        #     # image_buttonf = gr.Button(\"submit\")\n",
    "        #     image_buttons = gr.Button(\"submit\")\n",
    "        #     image_buttonr = gr.Button(\"reset\")\n",
    "        with gr.Accordion(\"Linear Low pass Filters\",open=False):\n",
    "            with gr.Accordion(\"traditional\",open=False):\n",
    "                k_t=gr.Slider(minimum=0,maximum=50,default=0,label=\"kernal\")\n",
    "            with gr.Accordion(\"gaussian\",open=False):\n",
    "                k_g=gr.Slider(minimum=0,maximum=50,default=0,label=\"kernal\")\n",
    "            filters=gr.inputs.CheckboxGroup([\"sharpening\",\"circular\",\"pyramidical\",\"confilter\"],label=\"filters\")\n",
    "         ####################################################################################################################   \n",
    "        with gr.Accordion(\"median\",open=False):\n",
    "            k_m=gr.Slider(minimum=0,maximum=50,default=0,label=\"kernal\")\n",
    "        ###################################################################################################################\n",
    "        with gr.Accordion(\"Linear High pass Filters\",open=False):\n",
    "            with gr.Accordion(\"Laplacian\",open=False):\n",
    "                k_l=gr.Slider(minimum=0,maximum=50,default=0,label=\"kernal\")\n",
    "            with gr.Accordion(\"sobel\",open=False):\n",
    "                sob=gr.inputs.CheckboxGroup([\"sobel of x\",\"sobel of y\",\"sobel of x and y\"],label=\"sobel\")\n",
    "                k_s=gr.Slider(minimum=0,maximum=50,default=0,label=\"kernal\")\n",
    "        with gr.Accordion(\"Thresholding\",open=False):\n",
    "            THRESH=gr.inputs.CheckboxGroup([\"THRESH_BINARY\",\"THRESH_BINARY_INV\",\"THRESH_TRUNC\",\"THRESH_TOZERO\",\"THRESH_TOZERO_INV\"],label=\"Thresholding\")\n",
    "            th=gr.Slider(minimum=0,maximum=255,default=0,label=\"value\")\n",
    "        \n",
    "        # image_buttons.click(smoothing, inputs=[imageInput,k_t,k_g,k_m,k_l,sob,k_s,THRESH,th,filters], outputs=imageOutput2) \n",
    "        # image_buttonr.click(rst,inputs=[imageInputs],outputs=imageOutputs)\n",
    "        image_buttonf.click(photoEditor, inputs=[imageInput,tx,ty,ang,flipp,power,ming,maxg,bits,s1,s2,x1,y1,brightnessSlider,contrastSlider,effectCheckboxes,\n",
    "                                                 k_t,k_g,k_m,k_l,sob,k_s,THRESH,th,filters,det,hist,log,neg,xs,ys], \n",
    "                            outputs=imageOutput2) \n",
    "        image_buttonr.click(rst,inputs=[imageInput],outputs=imageOutput2)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNSsLhTYu/W6rYS0jqBd1nd",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "PhotoEditor_opencv",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
